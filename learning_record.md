# 算法方向学习记录
## 一、决策树与随机森林
### 1、学习计划
之前对python有过粗略的了解,
自己主要使用c和c++语言编程,
学习到数据结构的树的部分,
需要将这部分知识内容与python的语法相对应,
随后额外学习文件操作、面向对象的编程、numpy数组操作、矩阵计算,
并逐步理解决策树、随机森林的相关内容。

根据上述学习流程,
使用deep seek帮助设计各阶段的小联系项目,
先后实现计算器和猜字游戏（基础语法适应）,
统计高频词和成绩管理系统（数据结构和文件操作）,
实现银行账户功能和模拟简单图书管理系统（面向对象编程）,
numpy实现矩阵乘法和生成随机数据集并计算统计指标（numpy与科学计算）,
最终实现单棵决策树与数据森林的实现。

### 2、学习实践

前两项任务均为利用原有知识编写成。

统计高频词任务则是通过学习Couter库函数中包括
但不限于
```
Couter()        统计已有列表中各种文字出现频率
most.common()   选择最高频的n个词
elements()      返回所有元素（按计数重复）
```
re库函数中
```
re.findall()    实现分词任务
```
并了解其中
```
r’\b\w+\b’
```
表示检索两头均为空格及标
点组成的词（包含数字、下划线、字母）, 这种表述可以
防止误判，但经过测试，在短文本中
```
\b\w+   \w+\b
```
在多种组合中均未出现误判的情况,
为保证严谨仍保留标准写法。此外,
还了解了调用文档的
```
open()    file()
```
以及相关用法
```
encoding    'utf-8'
```
前者表示编码方式,
后者则是在文本中出现汉字、日文等内容是必须选用的编码方式。

随后，进一步在编代码的过程中，一边学习新函数的用法。
例如
```
list()  dict()  match - case    in  is
lambda()    map()   filter()    reduce()
```
等数据结构、判断条件、函数的用

学习过程中编写的代码均存储在Github的master\practice python project
目录下，编写了除上述学习流程中任务除numpy应用以外的所有程序。

通过应用、思考、再应用的学习方式，在两天多的时间里具体详细的完成了决策树和
随机森林的构建。过程中对numpy的运算、树和森林的数据结构都有了较为深刻
和更具体的认识。此外，作为第一个自己独立完成的python可训练，具有一定预测
能力的程序，还成功实现了部分可视化，并在预测方面有较高成功率
自己还是比较满意和兴奋的
## 二、BERT的训练
### 学习过程
在经历过第一阶段任务的学习之后发现，如果像需要学习语法、函数库、以及逻辑框架
以实现某个工程任务的时候，真正的掌握每一块的内容固然可以较好地构建知识体系
但实际对工程来说，完成效率过低。完成python语法的学习以及决策树和随机森林花去了
过半的时间，因此决定在后面的学习中改为从代码中学习思考,
在实践中通过程序的修复与完善，调参与优化的过程中逐渐理解每一个需要利用到的
函数、代码，以此来提高针对性的效率。因而在学习过程中用到ai帮助解释特定函数用法
以及功能，针对性的对项目相关知识进行学习，效率得到有效的提高。先后完成了
对jsonl文件处理，pytorch、pandas使用以及Bert相关内容的学习，并成功
实现了爬虫数据清理，调用已下载的本地Bert模型进行训练，并最终实现
对某条评论分数进行预测的功能。相关参数的调试过程请见

 - **调参详细过程.md**

## 三、多头注意力
### 什么是多头注意力
- MHA
标准多头注意力 (Multi-Head Attention, MHA)
核心思想是将输入分为多个头（n_heads），每个头独立学习不同的注意力模式，最后合并结果。每个头拥有独立的 Q/K/V 投影矩阵。


- MQA
核心思想是将所有查询头共享同一个 Key 和 Value 投影，仅保留独立的 Query 投影，大幅减少参数和缓存


- GQA
核心思想是将多头分组（n_groups），组内共享 Key/Value 投影，组间独立，平衡效率与表达能力。
### 关键问题发现与改进思考

- 对角线模式有效性验证

理论预期：注意力权重应为对角线全1矩阵

实际输出：由于线性变换的存在，实际权重可能非严格对角（需通过可视化确认

### 感悟

- 理论到实践的鸿沟：

初学Transformer时认为注意力机制是"黑箱"，通过动手实现发现其本质是可解释的矩阵运算组合

- 核心难点在于维度变换与多头信息的合理拆分/重组

本次实践深刻揭示了多头注意力机制的内在机理，代码中的问题修正过程强化了对维度变换和参数独立性的理解。可视化结果验证了理论设计的正确性，也暴露出工程实现中的细节陷阱。未来的学习应继续深入结合理论推导与代码实现，同时探索注意力机制在长序列建模中的优化方法。




